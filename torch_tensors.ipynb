{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7020b6d7-49cd-4fca-84b9-123be9847765",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch Tensors\n",
    "\n",
    "This simple notebook introduces PyTorch tensors and shows how to convert back and forth between torch tensors and numpy arrays. \n",
    "\n",
    "**Sources:**\n",
    "- [Patrick Loeber](https://www.patrickloeber.com/)  \n",
    "- [PyTorch Turorials - Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)  \n",
    "- [Pytorch General Guide](https://pytorch.org/tutorials/beginner/basics/intro.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd1579-fd1a-4865-9ba3-d317f5075d7d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468ed498-ebd5-4941-98e5-af3cde72b7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7855744b-87f5-48e5-b469-053a1c9c8fda",
   "metadata": {},
   "source": [
    "### Scalar torch tensor\n",
    "\n",
    "First lets create a torch tensor containing a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d389fca-08cf-484f-91ec-5c3f2b451abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b407a-49d2-4703-9452-165c2aeb9342",
   "metadata": {},
   "source": [
    "### 1D torch tensor\n",
    "\n",
    "Lets now create a vector, similar to a numpy array with shape [n,1] or shape [n,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e73c2b0-50b4-4fa3-9d02-487decf4d6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5)\n",
    "x.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec72616-c177-42b3-82cb-4ba0a96707ef",
   "metadata": {},
   "source": [
    "### 2D torch tensor\n",
    "\n",
    "Let's create a 2D torch tensor, similar to a 2D numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1a2bfe-0e57-432b-ab16-af17fa09b72e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(3, 4)\n",
    "x.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d1e1d-7b39-4729-bc58-3d23f06f0233",
   "metadata": {},
   "source": [
    "### 3D torch tensor\n",
    "\n",
    "Let's also examine a 3D torch tensor, commonly used when processing image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a11032c-75c2-4e0e-a55c-5d6ac7f4d44d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 3)\n",
    "x.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f931e7-a96f-416d-885c-a4552e6eb3f1",
   "metadata": {},
   "source": [
    "### 4D torch tensor\n",
    "\n",
    "We can generate torch tensors with even higher dimensions such as a 4D torch tensor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3faf0719-9f03-4ed4-a424-144922a3daec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 2, 3)\n",
    "x.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0e287-a0a8-47e1-b7c8-283dcd813158",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "Similar to numpy, we can also generate matrices containing random values\n",
    "\n",
    "The values are drawn from a uniform distribution over the interval $[0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62928d25-f43b-4ad2-8cca-b4aa0dd2e826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1216, 0.1669, 0.8774, 0.8541],\n",
       "        [0.7493, 0.9617, 0.3434, 0.2318],\n",
       "        [0.3335, 0.3350, 0.1434, 0.7950]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b3121-6004-44d3-87fc-99a0a562a7fd",
   "metadata": {},
   "source": [
    "### Tesnsors filled with a single value\n",
    "\n",
    "Again similar to numpy we can generate a tensor filled with a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef34360-f6cc-45fc-beb7-e66f51c5a4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4577d73-1d66-4554-bc42-e499e6ad7f9d",
   "metadata": {},
   "source": [
    "### Altering the dtype in the tensor\n",
    "\n",
    "We can also specifgy the data type for the data stored in a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1212f5-ae2c-4f8b-b210-b8e68ece7836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float16)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, dtype=torch.int32)\n",
    "print(x)\n",
    "\n",
    "y = torch.ones(2, 3, dtype=torch.float16)\n",
    "print(y)\n",
    "\n",
    "z = torch.ones(2, 3, dtype=torch.float64)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b127d948-33d3-40bb-a2df-90aa10458308",
   "metadata": {},
   "source": [
    "### Obtain the size of a torch tensor\n",
    "\n",
    "This is very similar to numpy array's shape() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4af85db8-6555-4497-abbe-994a0af93443",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, dtype=torch.int32)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7acc1f-8d8f-4e02-bcfa-8009941cc210",
   "metadata": {},
   "source": [
    "### Generating a tensor from a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7ffe1cd-c2ba-424c-a1ae-e2a877e33c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ef474-4666-4768-b213-32d1e4f89ece",
   "metadata": {},
   "source": [
    "# Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0864b3-0b1f-40e1-af8f-4a6e6408e7b7",
   "metadata": {},
   "source": [
    "We can now add, subtract, divide, and multiply our torch tensors. \n",
    "\n",
    "We'll see how to apply both **element-wise** and **matrix** multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce91c33a-2067-43b0-ab05-c5475ed0ac3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1188, 0.4462],\n",
      "        [0.2256, 0.8137]])\n",
      "tensor([[0.8763, 0.9261],\n",
      "        [0.8501, 0.5577]])\n",
      "tensor([[0.9951, 1.3723],\n",
      "        [1.0757, 1.3714]])\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)\n",
    "z = x + y             #  <-- These two lines achieve the same thing\n",
    "z = torch.add(x, y)   #  <-- These two lines achieve the same thing\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2489af-0e93-4383-996b-c1150b996bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7576, -0.4800],\n",
      "        [-0.6245,  0.2561]])\n"
     ]
    }
   ],
   "source": [
    "# subtraction\n",
    "z = x - y                  #  <-- These two lines achieve the same thing\n",
    "z = torch.subtract(x, y)   #  <-- These two lines achieve the same thing\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f661069-c689-4583-96f1-1c131c46fb2e",
   "metadata": {},
   "source": [
    "### in-place operations\n",
    "\n",
    "Notice here how we can use **add_()** to do an in-place addition. Notice the trailing underscore here? Every operations in pytorch with a trailing underscore makes the update inplace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38e6c471-010a-42cb-abfe-31333cdefd96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9951, 1.3723],\n",
      "        [1.0757, 1.3714]])\n"
     ]
    }
   ],
   "source": [
    "# in-place addition\n",
    "y.add_(x)  # <-- updates y inplace\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d85330b4-e3cc-41d8-ad1c-25d95013579c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8763, 0.9261],\n",
      "        [0.8501, 0.5577]])\n"
     ]
    }
   ],
   "source": [
    "# in-place subtraction\n",
    "y.subtract_(x)  # <-- updates y inplace\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d66c1-318f-4970-b6e2-d863b0ff3907",
   "metadata": {},
   "source": [
    "### Tensor multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fc10b-67db-4bd3-8c01-3b7040a5c28a",
   "metadata": {},
   "source": [
    "**Element-wise multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bde24352-1b43-4a46-b65a-a36cc0d96783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5092, 0.6067],\n",
      "        [0.5029, 0.4416]])\n",
      "tensor([[0.9853, 0.8399],\n",
      "        [0.2461, 0.4486]])\n",
      "tensor([[0.5017, 0.5096],\n",
      "        [0.1238, 0.1981]])\n"
     ]
    }
   ],
   "source": [
    "# element-wise multiplication\n",
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)\n",
    "z = torch.multiply(x, y)   #  <-- These two lines achieve the same thing\n",
    "z = x * y                  #  <-- These two lines achieve the same thing\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b69c0-d181-467b-928c-38bde18d061a",
   "metadata": {},
   "source": [
    "**Element-wise division**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0045ddaf-fbf8-4356-8221-3b5beac1d219",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4379, 0.8128],\n",
      "        [0.8643, 0.8964]])\n",
      "tensor([[0.0581, 0.9350],\n",
      "        [0.5061, 0.1077]])\n",
      "tensor([[7.5406, 0.8693],\n",
      "        [1.7077, 8.3244]])\n"
     ]
    }
   ],
   "source": [
    "# element-wise division\n",
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)\n",
    "z = torch.div(x, y)        # <-- These two lines achieve the same thing\n",
    "z = x / y                  #  <-- These two lines achieve the same thing\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118b4b1-45a1-4f95-96e5-3db5cf9d784a",
   "metadata": {},
   "source": [
    "**Matrix Multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc302a7c-7901-4b83-a669-ace83f6b48d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5507, 0.1333],\n",
      "        [0.9063, 0.2442]])\n",
      "tensor([[0.9043, 0.9480],\n",
      "        [0.2478, 0.9752]])\n",
      "tensor([[0.5310, 0.6520],\n",
      "        [0.8801, 1.0973]])\n"
     ]
    }
   ],
   "source": [
    "# element-wise division\n",
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# matrix multiplication\n",
    "z = torch.matmul(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43428b-c398-4c68-9d69-f14bc88fd3b2",
   "metadata": {},
   "source": [
    "## Slicing Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54025154-f2e5-4b17-bb7b-af7efcc8ceea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0338, 0.8825, 0.6898],\n",
       "        [0.2414, 0.0794, 0.8200],\n",
       "        [0.3991, 0.0100, 0.0542],\n",
       "        [0.1904, 0.8649, 0.7281],\n",
       "        [0.6408, 0.2784, 0.7436]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899528c-e507-4958-b153-845d29362217",
   "metadata": {},
   "source": [
    "Similar to Numpy, we can slide the 2D array to retrieve only the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa61438-449c-440c-a9d0-b86f3170fd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0338, 0.2414, 0.3991, 0.1904, 0.6408])\n"
     ]
    }
   ],
   "source": [
    "# print the first column\n",
    "print(x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d744997d-b17b-4017-9a78-0b617d5a3172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0338, 0.8825, 0.6898])\n"
     ]
    }
   ],
   "source": [
    "# print the first row\n",
    "print(x[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "267c452b-3474-4a5a-8578-b17b35f9907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100)\n"
     ]
    }
   ],
   "source": [
    "# index an individual value\n",
    "print(x[2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6de70bbe-d74b-4452-bb89-8c4bd816d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009952843189239502\n"
     ]
    }
   ],
   "source": [
    "# here we can return the floating point value from the torch tensor contining a single value\n",
    "print(x[2, 1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52b02edc-872a-4e61-982d-2453490e7833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x[2, 1]))\n",
    "print(type(x[2, 1].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ccbb83-1bdf-4b17-a990-da4decac40fc",
   "metadata": {},
   "source": [
    "## Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5bca8bb-c4a5-4ae3-a1bd-71737ee82970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6595, 0.9184, 0.4075, 0.2779],\n",
       "        [0.4833, 0.5294, 0.6674, 0.4318],\n",
       "        [0.6629, 0.0059, 0.9440, 0.4606],\n",
       "        [0.8884, 0.9520, 0.1222, 0.1521]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e379fb2-1535-4fbe-8565-3f4a4287a903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6595, 0.9184, 0.4075, 0.2779, 0.4833, 0.5294, 0.6674, 0.4318, 0.6629,\n",
       "        0.0059, 0.9440, 0.4606, 0.8884, 0.9520, 0.1222, 0.1521])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape x into a tensory (y) with new dimensions\n",
    "y = x.view(16)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f717611-f1f8-41fb-912c-bfd42ee38962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6595, 0.9184],\n",
       "        [0.4075, 0.2779],\n",
       "        [0.4833, 0.5294],\n",
       "        [0.6674, 0.4318],\n",
       "        [0.6629, 0.0059],\n",
       "        [0.9440, 0.4606],\n",
       "        [0.8884, 0.9520],\n",
       "        [0.1222, 0.1521]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we can reshape to a tensor of shape (8, 2) and we can let PyTorch retrieve the value for the number of columns (2)\n",
    "y = x.view(8, -1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c36bc6d1-6763-4ab6-aef8-3079d1d55204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([4, 4])\n",
      "New shape: torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f'Original shape: {x.size()}')\n",
    "print(f'New shape: {y.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de29506-6c6f-44c2-8871-3d755d5041cb",
   "metadata": {},
   "source": [
    "## Converting between PyTorch tensors and Numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37b24367-bceb-489e-90cf-d234024fd7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aecd7154-0564-429c-a000-fc2afa80db20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "326eedf1-6cfc-46d1-914c-3255f59a95ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc8230-0552-43a3-be81-ae6d32d18baf",
   "metadata": {},
   "source": [
    "### NOTE: be careful here because a and b will share the same space in memory!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03492277-eade-48df-8f4f-1cfb88b9e50e",
   "metadata": {},
   "source": [
    "If we create a torch tensor called 'a' and then create a numpy array called 'b' using a.numpy(), then modifying 'a' will also modify 'b' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05c01b74-45cc-4281-bcb3-ae299e313ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old torch tensor: tensor([1., 1., 1., 1., 1.])\n",
      "Old numpy array: [1. 1. 1. 1. 1.]\n",
      "New torch tensor: tensor([2., 2., 2., 2., 2.])\n",
      "New numpy array: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "\n",
    "print(f'Old torch tensor: {a}')\n",
    "print(f'Old numpy array: {b}')\n",
    "\n",
    "b *= 2\n",
    "\n",
    "print(f'New torch tensor: {a}')\n",
    "print(f'New numpy array: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14207144-8200-40c4-9c4d-8fff71c52df5",
   "metadata": {},
   "source": [
    "So we can see where that modifying the array 'b' also modified the tensor 'a'\n",
    "\n",
    "**NOTE** This memory sharing does NOT occur if you're using GPU memory for torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4aa4afa-f9e8-458a-85d0-f7b4181bbd45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec4a4b-26c2-465f-957f-8f387fab3aa0",
   "metadata": {},
   "source": [
    "We can see here that cuda is not available, so PyTorch is relying only on CPU memory for storing torch tensors. Ergo, the numpy array copy of a torch tensor will share memory with the tensor itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ae0d9-d09a-44b5-b177-d88e24644282",
   "metadata": {},
   "source": [
    "## Utilizing CUDA and GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b3c15be-a435-4abc-b81e-2ddc4e0de06e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('CUDA is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6ab0f-60bf-4103-bff4-b2997c0e4c1b",
   "metadata": {},
   "source": [
    "Here we see that CUDA is not available. If it were, however, we could create a tensor on the GPU and then bring it back to CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85a2a722-f47c-493e-a784-a8babbb3dbde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('CUDA is available!')\n",
    "    \n",
    "    # define the GPU device \n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # store x as a torch tensor in GPU memory\n",
    "    x = torch.ones(5, device=device)\n",
    "    \n",
    "    # store y as a tensor in CPU memory and then move it over to GPU memory\n",
    "    y = torch.ones(5)\n",
    "    y.to(device)\n",
    "    \n",
    "    # perform an operation using the GPU (very fast!!)\n",
    "    z = x + y\n",
    "    \n",
    "    # be careful here... we need to move the 'z' tensor back to CPU memory before we can store it as a numpy array\n",
    "    z.to(\"cpu\")\n",
    "    \n",
    "    # and now we can store z as a numpy array in CPU memory\n",
    "    z_np = z.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5d14f-8d40-45e5-8c83-508b92a319e6",
   "metadata": {},
   "source": [
    "## Using 'requires_grad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df3ce661-62f4-45be-a7b4-2694f8ac5241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde6338-5a8f-4c42-b871-97ee8e7356f5",
   "metadata": {},
   "source": [
    "This stores the gradients of this tensor as we perform operations on the tensor. We will need this to be true (requires_grad=True) for any variable that we want to optimize. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
